<!-- # Copyright (c) 2025 takotime808 -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>{{ project_title or "Multi-Fidelity, Multi-Output Surrogate Modeling Report" }}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 30px; }
        h1, h2, h3 { color: #2d4059; }
        .section { margin-bottom: 2em; }
        .plot { max-width: 800px; margin: 1em 0; }
        table { border-collapse: collapse; margin: 1em 0; }
        th, td { border: 1px solid #ddd; padding: 8px; }
        th { background: #f4f4f4; }
        .errormsg { color: #d7263d; font-size: 1.1em; text-align: center; }
    </style>
</head>
<body>
    <h1>{{ project_title or "Multi-Fidelity, Multi-Output Surrogate Modeling Report" }}</h1>
    <div class="section">
        <h2>Overview</h2>
        <p>
            <i>
                This report summarizes the construction, evaluation, and interpretation of a multi-fidelity, multi-output surrogate model. 
                The report includes predictive performance, uncertainty quantification, and interpretability analyses for all model outputs and fidelities.
            </i>
        </p>
        <p>
            <b>Model type:</b> {{ model_type }}<br>
            <b>Fidelity levels:</b> {{ fidelity_levels|join(", ") if fidelity_levels else "N/A" }}<br>
            <b>Outputs:</b> {{ output_names|join(", ") if output_names else "N/A" }}<br>
            <b>Description:</b> {{ description or "No description provided." }}
        </p>
    </div>
    <div class="section">
        <h2>Regression Metrics</h2>
        <p>
            <i>
                The following table shows regression metrics (such as $R^2$, RMSE, MAE) for each output variable, quantifying model accuracy on the test data.
            </i>
        </p>
        <table>
            <tr>
                <th>Output</th>
                <th>RÂ²</th>
                <th>RMSE</th>
                <th>MAE</th>
                <th>Other</th>
            </tr>
            {% for name in output_names %}
            <tr>
                <td>{{ name }}</td>
                <td>{{ metrics[name]['r2']|round(3) }}</td>
                <td>{{ metrics[name]['rmse']|round(3) }}</td>
                <td>{{ metrics[name]['mae']|round(3) }}</td>
                <td>
                    {% for k,v in metrics[name].items() %}
                        {% if k not in ['r2','rmse','mae'] %}
                            <b>{{ k }}:</b> {{ v|round(3) }}<br>
                        {% endif %}
                    {% endfor %}
                </td>
            </tr>
            {% endfor %}
        </table>
    </div>
    <div class="section">
        <h2>Uncertainty Metrics</h2>
        <p>
            <i>
                These metrics assess how well the model's predictive uncertainties reflect the actual errors. Lower NLL, sharpness, and miscoverage indicate better calibrated uncertainty estimates.
            </i>
        </p>
        <table>
            <tr>
                <th>Metric</th>
                <th>Value</th>
            </tr>
            {% for k, v in uncertainty_metrics.items() %}
            <tr>
                <td>{{ k }}</td>
                <td>{{ v|round(3) }}</td>
            </tr>
            {% endfor %}
        </table>
        <h3>Uncertainty Toolbox Plots</h3>
        <p>
            <i>
                These plots visualize calibration, sharpness, and other aspects of model uncertainty quantification.
            </i>
        </p>
        {% for p in uncertainty_plots %}
        <div class="plot">
            {% if p.img_b64 %}
                <img src="data:image/png;base64,{{ p.img_b64 }}" alt="{{ p.title }}" style="width: 100%; max-width: 800px;">
            {% else %}
                <div class="errormsg">{{ p.errormsg or "Plot unavailable." }}</div>
            {% endif %}
            <div><b>{{ p.title }}</b></div>
            <div>{{ p.caption }}</div>
        </div>
        {% endfor %}
    </div>
    <!-- <div class="section">
        <h2>Predictions vs. True Values (per output)</h2>
        <p>
            <i>
                Each scatter plot below compares predicted vs. actual values for each output. Error bars (if shown) reflect predictive uncertainty.
            </i>
        </p>
        {% for name in output_names %}
        <h3>{{ name }}</h3>
        <div class="plot">
            {% if prediction_plots[name] %}
                <img src="data:image/png;base64,{{ prediction_plots[name] }}" alt="Pred vs True for {{ name }}">
            {% else %}
                <div class="errormsg">Prediction plot for {{ name }} is unavailable.</div>
            {% endif %}
        </div>
        {% endfor %}
    </div> -->
<div class="section">
        <h2>Predictions vs. True Values (per output)</h2>
        <p>
            <i>
                Each scatter plot below compares predicted vs. actual values for each output. Error bars (if shown) reflect predictive uncertainty.
            </i>
        </p>
        {% for name in (prediction_plots.keys()) %}
        <div class="plot">
            {% if prediction_plots[name] %}
                <img src="data:image/png;base64,{{ prediction_plots[name] }}" alt="Pred vs True for {{ name }}">
            {% else %}
                <div class="errormsg">Prediction plot for {{ name }} is unavailable.</div>
            {% endif %}
        </div>
        {% endfor %}
    </div>

    <div class="section">
        <h2>SHAP Explanations</h2>
        <p>
            <i>
                SHAP values show how each input feature influences model predictions for each output, helping identify key drivers of model behavior.
            </i>
        </p>
        {% for name in output_names %}
        <h3>{{ name }}</h3>
        <div class="plot">
            {% if shap_plots[name] %}
                <img src="data:image/png;base64,{{ shap_plots[name] }}" alt="SHAP for {{ name }}">
            {% else %}
                <div class="errormsg">SHAP plot for {{ name }} is unavailable.</div>
            {% endif %}
        </div>
        {% endfor %}
    </div>
    <div class="section">
        <h2>Partial Dependence Plots (PDP)</h2>
        <p>
            <i>
                PDPs illustrate how varying each feature affects model predictions for each output, providing insights into model sensitivity.
            </i>
        </p>
        {% for name in output_names %}
        <h3>{{ name }}</h3>
        <div class="plot">
            {% if pdp_plots[name] %}
                <img src="data:image/png;base64,{{ pdp_plots[name] }}" alt="PDP for {{ name }}">
            {% else %}
                <div class="errormsg">PDP plot for {{ name }} is unavailable.</div>
            {% endif %}
        </div>
        {% endfor %}
    </div>
    {% if pca_explained_variance %}
    <div class="section">
        <h2>PCA Explained Variance</h2>
        <p>
            <i>
                The following plot and table summarize the variance captured by each principal component.
            </i>
        </p>
        <div class="plot">
            {% if pca_variance_plot %}
                <img src="data:image/png;base64,{{ pca_variance_plot }}" alt="PCA Variance">
            {% endif %}
        </div>
        <table>
            <tr><th>Component</th><th>Explained Variance Ratio</th></tr>
            {% for var in pca_explained_variance %}
            <tr><td>PC{{ loop.index }}</td><td>{{ var|round(3) }}</td></tr>
            {% endfor %}
        </table>
    </div>
    {% endif %}
    <div class="section">
        <h2>Sampling & Input Space Visualization</h2>
        <p>
            <i>
                This section visualizes the distribution of the sampled input space and attempts to infer the sampling strategy used (e.g., LHS, random, grid).
            </i>
        </p>
        <div>
            <h3>Sampling Technique Inference</h3>
            <div class="plot">
                {% if sampling_umap_plot %}
                    <img src="data:image/png;base64,{{ sampling_umap_plot }}" alt="UMAP Sampling Plot">
                {% else %}
                    <div class="errormsg">Sampling UMAP plot is unavailable.</div>
                {% endif %}
            </div>
            <div>{{ sampling_method_explanation }}</div>
        </div>
        {% if sampling_other_plots %}
        {% for p in sampling_other_plots %}
        <div class="plot">
            {% if p.img_b64 %}
                <img src="data:image/png;base64,{{ p.img_b64 }}" alt="{{ p.title }}">
            {% else %}
                <div class="errormsg">{{ p.errormsg or "Sampling plot unavailable." }}</div>
            {% endif %}
            <div><b>{{ p.title }}</b></div>
        </div>
        {% endfor %}
        {% endif %}
    </div>
    <div class="section">
        <h2>Additional Diagnostics</h2>
        <p>
            <i>
                Other plots to support model diagnostics, including error histograms or domain-specific visualizations, are shown below.
            </i>
        </p>
        {% for p in other_plots %}
        <div class="plot">
            {% if p.img_b64 %}
                <img src="data:image/png;base64,{{ p.img_b64 }}" alt="{{ p.title }}">
            {% else %}
                <div class="errormsg">{{ p.errormsg or "Diagnostic plot unavailable." }}</div>
            {% endif %}
            <div><b>{{ p.title }}</b></div>
            <div>{{ p.caption }}</div>
        </div>
        {% endfor %}
    </div>
    <div class="section">
        <h2>Appendix: Methodology & Notes</h2>
        <p>
            <i>
                Summary of modeling methodology, dataset sizes, and miscellaneous notes.
            </i>
        </p>
        <p>
            <b>Training data size:</b> {{ n_train }}<br>
            <b>Test data size:</b> {{ n_test }}<br>
            <b>Cross-validation:</b> {{ cross_validation }}<br>
            <b>Random seed:</b> {{ seed }}
        </p>
        <p>
            <b>Notes:</b><br>
            {{ notes|replace('\n','<br>') }}
        </p>
    </div>
</body>
</html>
